Dataset ------------ glass ------------------------------------
------------------------------------------------------------------------------
Naive Bayes: ******************************************************************
Tuner's best parameters: {'var_smoothing': 1e-09}
Tuner's best F1 score: 0.3897609416727063
X_test F1 Score: 0.5603801169590643
X_test accuracy: 0.5116279069767442



XGBoost: **********************************************************************
Tuner's best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 20, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'subsample': 0.8}
Tuner's best F1 score: 0.7140350824698651
X_test F1 Score: 0.8348758521172314
X_test accuracy: 0.8837209302325582



IPS-KNN: **********************************************************************
Tuner's best parameters: {'k': 1}
Tuner's best F1 score: 0.5672825192436177
X_test F1 Score: 0.7765791556114136
X_test accuracy: 0.7441860465116279



KNN: **************************************************************************
Tuner's best parameters: {'n_neighbors': 1, 'weights': 'uniform'}
Tuner's best F1 score: 0.5672825192436177
X_test F1 Score: 0.7765791556114136
X_test accuracy: 0.7441860465116279



Logistic Regression: **********************************************************
Tuner's best parameters: {'C': 10000, 'penalty': 'l2', 'solver': 'lbfgs'}
Tuner's best F1 score: 0.6481064427641139
X_test F1 Score: 0.5505634437683119
X_test accuracy: 0.6511627906976745



SVM: **************************************************************************
Tuner's best parameters: {'C': 10.0, 'gamma': 'scale', 'kernel': 'linear'}
Tuner's best F1 score: 0.5402602710188916
X_test F1 Score: 0.6015151515151516
X_test accuracy: 0.6976744186046512



Decision Tree: ****************************************************************
Tuner's best parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10}
Tuner's best F1 score: 0.6142335210178348
X_test F1 Score: 0.49117647058823527
X_test accuracy: 0.627906976744186



Random Forest: ****************************************************************
Tuner's best parameters: {'bootstrap': False, 'max_depth': 15, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}
Tuner's best F1 score: 0.7259817360162188
X_test F1 Score: 0.8101120448179272
X_test accuracy: 0.8372093023255814



Dataset ------------ ionosphere ------------------------------------
------------------------------------------------------------------------------
Naive Bayes: ******************************************************************
Tuner's best parameters: {'var_smoothing': 1e-07}
Tuner's best F1 score: 0.9288279238142252
X_test F1 Score: 0.9183673469387755
X_test accuracy: 0.8873239436619719



XGBoost: **********************************************************************
Tuner's best parameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 3, 'subsample': 0.5}
Tuner's best F1 score: 0.9621484137345708
X_test F1 Score: 0.9387755102040816
X_test accuracy: 0.9154929577464789



IPS-KNN: **********************************************************************
Tuner's best parameters: {'k': 1}
Tuner's best F1 score: 0.8983620180988602
X_test F1 Score: 0.857142857142857
X_test accuracy: 0.7887323943661971



KNN: **************************************************************************
Tuner's best parameters: {'n_neighbors': 2, 'weights': 'uniform'}
Tuner's best F1 score: 0.9148965670234597
X_test F1 Score: 0.8737864077669902
X_test accuracy: 0.8169014084507042



Logistic Regression: **********************************************************
Tuner's best parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}
Tuner's best F1 score: 0.9192647037809257
X_test F1 Score: 0.9019607843137255
X_test accuracy: 0.8591549295774648



SVM: **************************************************************************
Tuner's best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}
Tuner's best F1 score: 0.9590449604534111
X_test F1 Score: 0.9484536082474228
X_test accuracy: 0.9295774647887324



Decision Tree: ****************************************************************
Tuner's best parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2}
Tuner's best F1 score: 0.9266463382239035
X_test F1 Score: 0.9462365591397849
X_test accuracy: 0.9295774647887324



Random Forest: ****************************************************************
Tuner's best parameters: {'bootstrap': False, 'max_depth': 5, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}
Tuner's best F1 score: 0.9564406511774933
X_test F1 Score: 0.9387755102040816
X_test accuracy: 0.9154929577464789



Dataset ------------ page_blocks ------------------------------------
------------------------------------------------------------------------------
Naive Bayes: ******************************************************************
Tuner's best parameters: {'var_smoothing': 1e-09}
Tuner's best F1 score: 0.5866090571948759
X_test F1 Score: 0.5547195457950355
X_test accuracy: 0.8958904109589041



XGBoost: **********************************************************************
Tuner's best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'reg_alpha': 1e-05, 'reg_lambda': 1e-05, 'scale_pos_weight': 1, 'subsample': 0.5}
Tuner's best F1 score: 0.8565020706584148
X_test F1 Score: 0.8673838347895538
X_test accuracy: 0.9780821917808219



IPS-KNN: **********************************************************************
Tuner's best parameters: {'k': 8}
Tuner's best F1 score: 0.8049757588088612
X_test F1 Score: 0.8140152559307919
X_test accuracy: 0.9726027397260274



KNN: **************************************************************************
Tuner's best parameters: {'n_neighbors': 8, 'weights': 'distance'}
Tuner's best F1 score: 0.8013277999425809
X_test F1 Score: 0.8157543107544953
X_test accuracy: 0.9726027397260274



Logistic Regression: **********************************************************
Tuner's best parameters: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}
Tuner's best F1 score: 0.7824970489128502
X_test F1 Score: 0.8221809972614201
X_test accuracy: 0.9662100456621004



SVM: **************************************************************************
Tuner's best parameters: {'C': 0.8, 'gamma': 'scale', 'kernel': 'linear'}
Tuner's best F1 score: 0.764534248161734
X_test F1 Score: 0.7231717426606237
X_test accuracy: 0.9625570776255707



Decision Tree: ****************************************************************
Tuner's best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2}
Tuner's best F1 score: 0.781693855543928
X_test F1 Score: 0.7300049972701762
X_test accuracy: 0.954337899543379



Random Forest: ****************************************************************
Tuner's best parameters: {'bootstrap': True, 'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}
Tuner's best F1 score: 0.8620698378487559
X_test F1 Score: 0.8457568993730487
X_test accuracy: 0.9698630136986301



Dataset ------------ waveform ------------------------------------
------------------------------------------------------------------------------
Naive Bayes: ******************************************************************
Tuner's best parameters: {'var_smoothing': 1e-09}
Tuner's best F1 score: 0.8007683134743642
X_test F1 Score: 0.7816811349291738
X_test accuracy: 0.795



XGBoost: **********************************************************************
Tuner's best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1e-05, 'scale_pos_weight': 1, 'subsample': 0.5}
Tuner's best F1 score: 0.8652510749125218
X_test F1 Score: 0.8433871000487251
X_test accuracy: 0.844



IPS-KNN: **********************************************************************
Tuner's best parameters: {'k': 24}
Tuner's best F1 score: 0.8484081840291344
X_test F1 Score: 0.82698822141694
X_test accuracy: 0.83



KNN: **************************************************************************
Tuner's best parameters: {'n_neighbors': 70, 'weights': 'uniform'}
Tuner's best F1 score: 0.8560916147250873
X_test F1 Score: 0.8379802706781961
X_test accuracy: 0.84



Logistic Regression: **********************************************************
Tuner's best parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}
Tuner's best F1 score: 0.8729348514846734
X_test F1 Score: 0.8623679947421063
X_test accuracy: 0.863



SVM: **************************************************************************
Tuner's best parameters: {'C': 0.8, 'gamma': 0.01, 'kernel': 'rbf'}
Tuner's best F1 score: 0.8727677519371857
X_test F1 Score: 0.8538723664951043
X_test accuracy: 0.855



Decision Tree: ****************************************************************
Tuner's best parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10}
Tuner's best F1 score: 0.7566380811279555
X_test F1 Score: 0.7380989407670956
X_test accuracy: 0.738



Random Forest: ****************************************************************
Tuner's best parameters: {'bootstrap': True, 'max_depth': 15, 'max_features': 'sqrt', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 1000}
Tuner's best F1 score: 0.8588869287204745
X_test F1 Score: 0.842283574759633
X_test accuracy: 0.843



